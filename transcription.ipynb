{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9gnJPUZkl+20ORTdqT2Q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TSGUSA/Transcription-whisper/blob/main/transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q openai-whisper ffmpeg-python\n",
        "\n",
        "# Import required libraries\n",
        "import whisper\n",
        "import torch\n",
        "import gc\n",
        "from google.colab import files\n",
        "\n",
        "# Clear GPU memory to prevent memory issues\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Welcome message\n",
        "print(\"üåü Welcome to the Whisper Transcription Tool! üåü\")\n",
        "print(\"This tool will transcribe your audio file into text using OpenAI's Whisper model.\")\n",
        "print(\"Please upload an audio file (MP3, WAV, M4A, etc.) when prompted.\\n\")\n",
        "\n",
        "# Upload an audio file\n",
        "print(\"üìÇ Step 1: Upload your audio file\")\n",
        "uploaded = files.upload()\n",
        "audio_file = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "print(f\"‚úÖ File '{audio_file}' uploaded successfully!\\n\")\n",
        "\n",
        "# Load the Whisper model\n",
        "print(\"ü§ñ Step 2: Loading the Whisper model...\")\n",
        "model = whisper.load_model(\"large-v3-turbo\")  # Use \"base\" for faster results; change to \"medium\" or \"large\" for better accuracy\n",
        "print(\"‚úÖ Model loaded successfully!\\n\")\n",
        "\n",
        "# Transcribe the uploaded audio file\n",
        "print(\"üéôÔ∏è Step 3: Transcribing your audio file...\")\n",
        "print(\"This may take a while depending on the size of the file and the model you selected.\")\n",
        "print(\"Please wait...\\n\")\n",
        "\n",
        "# Transcribe with verbose output for progress updates\n",
        "result = model.transcribe(audio_file, verbose=True)\n",
        "\n",
        "# Print the transcribed text\n",
        "print(\"\\nüéâ Transcription Complete! Here's the result:\\n\")\n",
        "print(result[\"text\"])\n",
        "\n",
        "# Save the transcription to a text file\n",
        "output_file = audio_file + \"_transcription.txt\"\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])\n",
        "\n",
        "print(f\"\\nüíæ Transcription saved to '{output_file}' in your Colab workspace.\")\n",
        "\n",
        "# Automatically download the transcription file\n",
        "files.download(output_file)\n",
        "print(f\"üì• File '{output_file}' has been downloaded automatically.\")"
      ],
      "metadata": {
        "id": "31GkuDQKv7ln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}